{
  "Qdrant": {
    "Url": "http://localhost:6343/",
    "Port": 6333
  },
  "DockerLaunch": {
    "DockerSettings": [
      {
        "ImageName": "qdrant/qdrant:latest",
        "HostPort": 6343,
        "ContainerPort": 6333,
        "WaitForPort": 6333,
        "HostPath": "/temp/test_qdrant_storage",
        "ContainerPath": "/qdrant/storage"
      }
    ]
  },
  "OpenAI": {
    "ApiKey": "<openai api key>",
    "OrganisationKey": "<organisation key>",
    "OpenAIUri": "https://api.openai.com/v1/"
  },
  "AzureOpenAI": {
    "ApiKey": "<azure openai api key>",
    "Endpoint": "",
    "ChatDeploymentName": ""
  },
  "LlamaModel": {
    "modelPath": "LlamaModels\\llama-2-7b.ggmlv3.q8_0.bin"
  },
  "Serilog": {
    "MinimumLevel": {
      "Default": "Verbose",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "outputTemplate": "{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] ({Application}/{MachineName}/{ThreadId}) {Message:lj}{NewLine}{Exception}"
        }
      },
      { "Name": "DiagnosticTrace" }
    ],
    "Enrich": [ "FromLogContext", "WithMachineName", "WithThreadId", "WithExceptionDetails" ],
    "Properties": {
      "Application": "SemanticKernel.Integration.Tests"
    }
  }
}
